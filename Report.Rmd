---
title: "Report on my own edx project"
author: "FUNG CHE HEI"
date: "8/19/2020"
output: pdf_document
---

```{r setup, set.seed(1), include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
```


```{r, echo=FALSE, message=FALSE}
#install packages that have not been downloaded
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(dslabs)) install.packages("dslabs", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitt", repos = "http://cran.us.r-project.org")
if(!require(plyr)) install.packages("plyr", repos = "http://cran.us.r-project.org")
if(!require(DMwR)) install.packages("DMwR", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(pROC)) install.packages("pROC", repos = "http://cran.us.r-project.org")
if(!require(ROCit)) install.packages("ROCit", repos = "http://cran.us.r-project.org")

#import any necessary library
library(tidyverse)
library(caret)
library(data.table)
library(readr)
library(dslabs)
library(caret)
library(lubridate)
library(corrplot)
library(knitr)
library(plyr)
library(DMwR)
library(randomForest)
library(rpart)
library(pROC)
library(ROCit) 

#Read csv data first, and then change them into data frame
seismic <- as.data.frame(read_csv("data/seismic_bumps.csv"))
```

# 1. Introduction

## 1.1 Background

There are many valuable minerals and geological materials in the Earth that are stored in the form of some kinds of ores, lode, vein and reef.  Mining is the human activities to extract those of them. Although mining activity seems interesting for human to discover different kinds of minerals in the Earth, it is a dangerous activities because a hazard of seismic bumps would occurs in many underground mines. Inaccurate prediction and detection would cause great damage to human life.

Therefore a good seismic hazard assessment is important and required for mining activities. With the aid of machine learning technologies, some research including clustering [1] and artificial neural networks [2] are used for prediction of seismic tremors in the past years.

## 1.2 Aim

Our main aim is:

* To forecast whether the high energy seismic bumps (higher than 10^4 J) would occur in coal mine in next shift, in order to predict whether the coal mine is under hazardous state or non-hazardous state.

With predicting the possibility of the occurrence of hazardous situation, appropriate risk assement and supervision service can be made. For example, reducing the risk of rockburst by the use of distressing shooting method and withdrawing workers from the threatened area.

## 1.3 Data set Information

The data set used is called "seismic-bumps Data Set" which is downloaded from UCI Machine Learning Repository. <https://archive.ics.uci.edu/ml/datasets/seismic-bumps#>

Here we read the downloaded data set and call it 'seismic'.

```{r, echo=TRUE,eval=FALSE}
seismic <- as.data.frame(read_csv("data/seismic_bumps.csv"))
```

### An overview on the seismic-bumps Data Set

```{r, echo=TRUE}
nrow(seismic)
```

```{r, echo=TRUE}
ncol(seismic)
```

```{r, echo=TRUE}
head(seismic)
```


After having a quick look on the data set, there are `r nrow(seismic)` rows (observations) and `r ncol(seismic)` columns (attributes). Each observation contains a summary statement about seismic activity in the rock mass within one shift (8 hours) which will be described in section 1.4, to predict 'hazardous' (positive class with value = 1) and 'non-hazardous' (negative class with value = 0) states. If 'hazardous' is predicted, it is possibly that seismic bump with an energy higher than 10^4 J would occur in the next shift. 

Here note the there is unbalanced distribution of positive and negative class. Among `r nrow(seismic)` observations, only `r sum(seismic$class == 1)` of them are positive class.

```{r, echo=TRUE}
sum(seismic$class == 1)
```


## 1.4 Arributes Information

* 1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic 
method (a - lack of hazard, b - low hazard, c - high hazard, d - danger state); 
* 2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the 
seismoacoustic method; 
* 3. shift: information about type of a shift (W - coal-getting, N -preparation shift); 
* 4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of 
geophones monitoring the longwall; 
* 5. gpuls: a number of pulses recorded within previous shift by GMax; 
* 6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded 
during eight previous shifts; 
* 7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number of pulses recorded during eight previous shifts; 
* 8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the 
seismoacoustic method based on registration coming from GMax only; 
* 9. nbumps: the number of seismic bumps recorded within previous shift; 
* 10. nbumps2: the number of seismic bumps (in energy range [10^2, 10^3)) registered within previous shift; 
* 11. nbumps3: the number of seismic bumps (in energy range [10^3, 10^4)) registered within previous shift; 
* 12. nbumps4: the number of seismic bumps (in energy range [10^4, 10^5)) registered within previous shift; 
* 13. nbumps5: the number of seismic bumps (in energy range [10^5, 10^6)) registered within the last shift; 
* 14. nbumps6: the number of seismic bumps (in energy range [10^6, 10^7)) registered within previous shift; 
* 15. nbumps7: the number of seismic bumps (in energy range [10^7, 10^8)) registered within previous shift; 
* 16. nbumps89: the number of seismic bumps (in energy range [10^8, 10^10)) registered within previous shift; 
* 17. energy: total energy of seismic bumps registered within previous shift; 
* 18. maxenergy: the maximum energy of the seismic bumps registered within previous shift; 
* 19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift 
('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift 
('non-hazardous state').

## 1.5 Variables Information

There are totally 18 input variables (attributes) and 1 binary output variable (class) in the data set.
The below table summarize some information of the variables.

```{r, echo=FALSE,message=FALSE,warning=FALSE, results='asis'}
variable_summary<-seismic %>% summarise_all(funs("Total" = n(),
                     "Filled" = sum(!is.na(.)),
                     "Nulls" = sum(is.na(.)),
                     "Cardinality" = length(unique(.)))) %>%
  melt() %>%
  separate(variable, into = c('variable', 'measure'), sep="_") %>%
  spread(measure, value)  %>%
  mutate(Uniqueness = format(round(Cardinality/Total,1), nsmall = 1))

kable(variable_summary[,c(1,2,3,4,5,6)], caption = "Variable Summary Table")
```

Although 'maxenergy' and 'nbumps' are numeric data representing the magnitude of energy and number of bumps respectively, they have a relatively small cardinality which result in zero Uniqueness (defined by the ratio of Cardinality to Total). Therefore they are classified into categorical variables. For those variables with uniqueness greater than zero are then classified as numeric variables. Below is the table that summarizing the variable type of class and each attributes.

```{r}
names<- variable_summary$variable[-8] #remove id
kable(data.frame(Variable = names, 
           Type = c('binary','numeric','numeric','numeric','numeric','catagorical','numeric',
                    'catagorical','catagorical','catagorical','catagorical','catagorical','catagorical',
                    'catagorical','catagorical','catagorical','catagorical','catagorical','catagorical')), caption = "Variable Type")
```


## 1.6 Key Steps

***

# 2. Data Analysis

## 2.1 Data Cleaning

### 2.1.1 Present of Nulls 

Refer to Table 1 in section 1.5, there is no Null value in the data set therefore removing of those null values is not required.

### 2.1.2 Statistic

Statistic of attributes is presented as follow: 
    
```{r, echo=TRUE}
summary(seismic)
```

Refer to the above summary and looking at attributes 'nbumps6', 'nbumps7' and 'nbumps89', it is observed all the values are zero which means those of them do not provide any information for classifying positive and negative class. Therefore, we remove 'nbumps6', 'nbumps7' and 'nbumps89' from the entire data set. For the attribute 'id', it can be regarded as primary key of the data set and do not use for binary classification.
    
### 2.1.3 Correctness

It is obvious that the total number of seismic bumps (nbumps) equals to the sum of seismic bumps with different energy levels (nbumps2 + nbumps3 + ... + nbumps7 + nbumps89) and they should have no difference. The below code test this fact to ensure the correctness of the data set.

```{r, echo=TRUE}
#test the correctness of the data set
seismic %>% 
  mutate(total = nbumps2+nbumps3+nbumps4+nbumps5+nbumps6+nbumps7+nbumps89) %>%
  mutate(diff = total - nbumps) %>%
  filter(diff!=0) %>% 
  dplyr::summarize(n=n()) %>%
  pull(n)
```

From the above result we can see that two observations suffer from the problem of inconsistency of the number of seismic bumps. Therefore these two observations will be removed from the entire data set and we call the corrected data set 'corrected_seismic'.

```{r, echo=TRUE,eval=FALSE}
#extract the index of incorrect data set
incorrect_index<- 
  seismic %>% 
  mutate(total = nbumps2+nbumps3+nbumps4+nbumps5+nbumps6+nbumps7+nbumps89) %>%
  mutate(diff = total - nbumps) %>%
  filter(diff!=0) %>% 
  pull(id)

#filter out the incorrect observations
#correct the data set
corrected_seismic<-
  seismic %>% 
  filter(id!=incorrect_index) %>%
  select(-nbumps6,-nbumps7,-nbumps89,-id)
```


## 2.2 Data Exploration and Visualization

### 2.2.1 Distribution of seismic (result of shift seismic hazard assessment) on mine with hazardous and non-hazardous state

In this section, the distribution of the result of shift seismic hazard assessment obtained by seismic method on mine with hazardous state and non-hazardous state is visualized. We can observe that the distribution of assessment result a (lack of hazard) and b (low hazard) is almost the same in mine with hazardous state. While the distribution of assessment result a (lack of hazard) is much higher than b (low hazard) in mine with non-hazardous state. The result is quite make sense since the mine with non-hazardous state should be more safe than that with  hazard state which is supported by the result of hazard assessment.

```{r, echo=FALSE, figures-side, fig.show="hold", out.width="50%"}
#extract the index of incorrect data set
incorrect_index<- 
  seismic %>% 
  mutate(total = nbumps2+nbumps3+nbumps4+nbumps5+nbumps6+nbumps7+nbumps89) %>%
  mutate(diff = total - nbumps) %>%
  filter(diff!=0) %>% 
  pull(id)

#filter out the incorrect observations
#correct the data set
corrected_seismic<-
  seismic %>% 
  filter(id!=incorrect_index) %>%
  select(-nbumps6,-nbumps7,-nbumps89,-id)

corrected_seismic %>%
  filter(class==1) %>%
  ggplot(aes(seismic)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  xlab("a - lack of hazard, b - low hazard") +
  ggtitle("seismic distribution on hazardous state \n(class 1)")

corrected_seismic %>%
  filter(class==0) %>%
  ggplot(aes(seismic)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  xlab("a - lack of hazard, b - low hazard") +
  ggtitle("seismic distribution on non-hazardous state \n(class 0)")
```


### 2.2.2 Distribution of seismoacoustic (result of shift seismic hazard assessment) on mine with hazardous and non-hazardous state

Similar to the previous section, the distribution of the result of shift seismic hazard assessment on mine with hazardous state and non-hazardous state is visualized, but the assessment result is obtained by seismoacoustic method. This time we can observe that the distribution of assessment result a (lack of hazard), b (low hazard) and c (high hazard) are almost the same in mine with hazardous state and non-hazardous state. This is pretty much surprise because we can deduce from the result that possibly the seismic hazard assessment result do not affect whether the mine is to be classified as hazardous or non-hazardous. The main reason may cause by the method used for hazard assessment this time is different from the previous one.

```{r, echo=FALSE, fig.show="hold", out.width="50%"}
corrected_seismic %>%
  filter(class==1) %>%
  ggplot(aes(seismoacoustic)) +
  geom_bar(width = 0.2,fill="red",col="black") +
  xlab("a - lack of hazard, b - low hazard, c - high hazard") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("seismoacoustic distribution on hazardous state \n(class 1)")

corrected_seismic %>%
  filter(class==0) %>%
  ggplot(aes(seismoacoustic)) +
  geom_bar(width = 0.2,fill="red",col="black") +
  xlab("a - lack of hazard, b - low hazard, c - high hazard") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("seismoacoustic distribution on non-hazardous state \n(class 0)")
```

### 2.2.3 Distribution of shift type on mine with hazardous and non-hazardous state

The effects of shift type (coal-getting or preparation) on seismic hazard of mine can be observed in the below graphs. Comparing to mine with non-hazardous state, it clearly shows that the ratio of W to N (i.e. the ratio of time period of coal-getting to preparation in mine) is much higher in mine with hazardous state. This comes to a reasonable observation because there is a possibility that coal-getting activity would trigger a high energy seismic bumps.

```{r, echo=FALSE, fig.show="hold", out.width="50%"}
corrected_seismic %>%
  filter(class==1) %>%
  ggplot(aes(shift)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  xlab("type of a shift (W - coal-getting, N -preparation shift)") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("shift type distribution on hazardous state \n(class 1)")

corrected_seismic %>%
  filter(class==0) %>%
  ggplot(aes(shift)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  xlab("type of a shift (W - coal-getting, N -preparation shift)") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("shift type distribution on non-hazardous state \n(class 0)")
```

### 2.2.4 Seismic energy recorded in previous shift (genergy) in mine with hazardous and non-hazardous state

This presents the records of seismic energy registered by the most active geophone (GMax) in the previous shift in both classes (i.e. mine with hazardous and non-hazardous state). By observing the below graph, the quartiles of seismic energy are having a higher value in mine with hazardous state than mine with non-hazardous state. It shows that the magnitude of previous seismic energy gives a significant effect on energy of seismic bumps in the next shift. That is, the higher the previous seismic energy is, the higher the chance of high energy seismic bump happens in the next shift. 

Another thing we observed from the findings is that the range is larger, and the quartile range is smaller in the negative class data set. The reason of this fluctuation may be due to the imbalance number of observations in positive class and negative class.

```{r}
corrected_seismic %>% 
  mutate(genergy_tran = genergy+1) %>%
  ggplot(aes(genergy_tran)) +
  geom_boxplot(fill="white") +
  scale_x_continuous(trans = "log10") +
  xlab("log(seismic energy in previous shift) / J") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  facet_grid(class~.) +
  ggtitle("genergy in mine with hazardous state (class 1) and non-hazardous state (class 0)")

```

### 2.2.5 Deviation of Seismic energy recorded in previous shift (gdenergy) in mine with hazardous and non-hazardous state

In this section, the deviation of records of seismic energy registered by the most active geophone (GMax) in previous shift in both classes (i.e. mine with hazardous and non-hazardous state) is presented in below graph. It is observed that other than the upper range, the distribution of deviation of seismic energy in the previous shift is almost the same in both classes (i.e. mine with hazardous state and non-hazardous state). Therefore the information given by the deviation of seismic energy in the previous shift may have a less effect on the prediction of occurrence of high energy seismic bumps in the next shift.

The difference in range of data set may cause by the imbalance number of observations in positive class and negative class. 

```{r}
corrected_seismic %>% 
  mutate(gdenergy_absolute = ifelse(gdenergy<0,-gdenergy,gdenergy)) %>%
  mutate(gdenergy_tran = ifelse(gdenergy_absolute==0,gdenergy_absolute+1,gdenergy_absolute)) %>%
  ggplot(aes(gdenergy_tran)) +
  geom_boxplot(fill="white") +
  scale_x_continuous(trans = "log10") +
  xlab("log(deviation of seismic energy in previous shift) / J") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  facet_grid(class~.) +
  ggtitle("gdenergy in mine with hazardous state (class 1) and non-hazardous state (class 0)")
```

### 2.2.6 Number of pulses recorded in previous shift (gpuls) in mine with hazardous and non-hazardous state

The below graph shows the distribution of number of seismic pulses recorded in previous shift on the two classes (i.e. mine with hazardous and non-hazardous state). It is observed that the more the seismic pulses recorded in the previous shift, the higher chance the high energy seismic bump occurs in the next shift.From this observation, 'gpuls' seems a good attribute for classifying whether the mine is in hazardous state or non-hazardous state.

```{r}
mu_gpuls <- ddply(corrected_seismic,"class", summarise, grp.mean=mean(gpuls))
corrected_seismic %>% 
  mutate(class = as.character(class)) %>%
  ggplot(aes(gpuls,fill=class)) +
  geom_density(alpha=0.4) +
  geom_vline(data=mu_gpuls, aes(xintercept=grp.mean, color=class),
             linetype="dashed") +
  scale_x_continuous(trans = "log10") +
  xlab("log(Number of pulses in previous shift)") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  ggtitle("gpuls in mine with hazardous state (class 1) and non-hazardous state (class 0)")
```

### 2.2.7 Deviation of number of pulses recorded in previous shift (gdpuls) in mine with hazardous and non-hazardous state

Here we try to observe how deviation of number of seismic pulses recorded in the previous shift would affect the occurrence of high energy bumps in next shift. In the below graph, the distributions of deviation of number of pulses in the previous shift are seem to be similar in two classes. An increase or decrease in number of seismic pulses in the previous shift seems not providing enough information for predicting the occurrence of high energy seismic bump in the next shift.

```{r}
mu_gdpuls <- 
  ddply(corrected_seismic %>% 
        mutate(gdpuls_absolute = ifelse(gdpuls<0,-gdpuls,gdpuls)),
      "class", summarise, grp.mean=mean(gdpuls_absolute))

corrected_seismic %>% 
  mutate(class = as.character(class)) %>%
  mutate(gdpuls_absolute = ifelse(gdpuls<0,-gdpuls,gdpuls)) %>%
  mutate(gdpuls_tran = ifelse(gdpuls_absolute==0,gdpuls_absolute+1,gdpuls_absolute)) %>%
  ggplot(.,aes(x=gdpuls_tran,fill=class)) +
  geom_density(alpha=0.4) +
  geom_vline(data=mu_gdpuls, aes(xintercept=grp.mean, color=class),
             linetype="dashed") +  
  scale_x_continuous(trans = "log10") +
  xlab("log(Deviation of number of pulses in previous shift)") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  ggtitle("gdpuls in mine with hazardous state (class 1) and non-hazardous state (class 0)")
```

### 2.2.8 Distribution of ghazard (result of shift seismic hazard assessment) on mine with hazardous and non-hazardous state

Similar to section 2.2.2, in each of the class (i.e. mine with hazardous and non-hazardous state), distribution of results of hazard assessment is summarized in the below graphs. With keeping the use of seismoacoustic method, only the observations coming from the most active geophone (GMax) are registered. The result is a bit unexpected because in negative class (mine with non-hazardous state), some hazard assessment with result c (high hazard) is recorded while there is no such assessment result recorded in positive class (mine with hazard state). This may due to again the imbalance number of opbservations in positive class and negative class. 

```{r, echo=FALSE, fig.show="hold", out.width="50%"}
corrected_seismic %>%
  filter(class==1) %>%
  ggplot(aes(ghazard)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  xlab("a - lack of hazard, b - low hazard") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("ghazard distribution on mine with hazardous state (class 1)")
  

corrected_seismic %>%
  filter(class==0) %>%
  ggplot(aes(ghazard)) +
  geom_bar(width = 0.1,fill="red",col="black") +
  xlab("a - lack of hazard, b - low hazard, c - high hazard") +
  theme_bw() +
  theme(plot.title = element_text(size = 15, face = "bold")) +
  ggtitle("ghazard distribution on mine with non-hazardous state (class 0)")
```

### 2.2.9 Number of seismic bumps with different energy levels in previous shift on mine with hazardous and non-hazardous state

From the below graphs, although the total numbers of seismic bumps recorded in the previous shift are different in two classes, it is interesting to observed that the distributions of seismic bumps in different energy ranges are almost the same. This result gives us a valuable information that the distribution of seismic bumps with different energy ranges in previous shift may has no main effect on causing a high energy seismic bump in the next shift.

```{r, include=FALSE}
#In each class, calculate total numbers of bumps with diff. energy range 
corrected_seismic %>%
  select(class,nbumps,nbumps2,nbumps3,nbumps4,nbumps5) %>%
  group_by(class) %>%
  summarize(sum(nbumps),sum(nbumps2),sum(nbumps3),sum(nbumps4),sum(nbumps5))
#create two data frames for each class   
bumps_c0<- data.frame(bumps_sum = c(1856,848,847,150,11))
bumps_c1<- data.frame(bumps_sum = c(362,168,168,25,1))
```


```{r, echo=FALSE, fig.show="hold", out.width="50%"}
###plot the positive class and negative class result
ggplot(bumps_c1, aes(x=c('total no. of bumps',
                         'no. of bumps in \nenergy range [10^2, 10^3)',
                         'no. of bumps in \nenergy range [10^3, 10^4)',
                         'no. of bumps in \nenergy range [10^4, 10^5)',
                         'no. of bumps in \nenergy range [10^5, 10^6)'),
                     y=bumps_sum)) +
  geom_col(fill="red",color="black", width = 0.2) +
  xlab("") +
  ylab("count") +
  theme_bw() +
  theme(plot.title = element_text(size = 12, face = "bold"),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Number of seismic bumps with different energy range on \nmine with hazardous state (class 1)")

ggplot(bumps_c0, aes(x=c('total no. of bumps',
                     'no. of bumps in \nenergy range [10^2, 10^3)',
                     'no. of bumps in \nenergy range [10^3, 10^4)',
                     'no. of bumps in \nenergy range [10^4, 10^5)',
                     'no. of bumps in \nenergy range [10^5, 10^6)'), 
                     y=bumps_sum)) +
  geom_col(fill="red",color="black", width = 0.2) +
  xlab("") +
  ylab("count") +
  theme_bw() +
  theme(plot.title = element_text(size = 12, face = "bold"),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Number of seismic bumps with different energy range on \nmine with non-hazardous state (class 0)")
```

### 2.2.10 Total energy of seismic bumps in previous shift on mine with hazardous and non-hazardous state

The below graph presents the total energy of seismic bumps registered in previous shift in both classes. Although the mean values of total energy are close to each other, the mean in negative class is only caused and calculated by 30 percent of it's observations. At most time (about 70 percent of the observations), the total energy of seismic bumps recorded in previous shift is zero in non-hazardous mine. While in the mine with hazardous state, about 75 percent of time there is a seismic bump with high energy level (10^3 to 10^5 J) occur in the previous shift. It then comes to a very useful information for predicting the occurrence of high energy seismic bumps in next shift.

```{r, echo=FALSE}
mu_energy <- ddply(corrected_seismic,"class", summarise, grp.mean=mean(energy))
corrected_seismic %>%
  mutate(class = as.character(class)) %>%
  mutate(energy_tran = energy+1) %>%
  ggplot(aes(energy_tran,fill=class)) +
  geom_density(alpha=0.4) +
  geom_vline(data=mu_energy, aes(xintercept=grp.mean, color=class),
             linetype="dashed") +
  scale_x_continuous(trans = "log10") +
  xlab("log(Total energy of seismic bumps in previous shift) / J") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  ggtitle("Total energy of seismic bumps in previous shift on mine with\nhazardous state (class 1) and non-hazardous state (class 0))")
```


### 2.2.11 Maximum energy of seismic bumps in previous shift on mine with hazardous and non-hazardous state

A very similar result is obtained when we observe the relationship between the Maximum energy of seismic bumps recorded in previous shift and the occurrence of high energy seismic bumps in next shift. It may due to the reason that the Maximum seismic energy recorded in previous shift takes almost the while part of the total seismic energy recorded in previous shift (i.e. maxenergy / total energy approximately equal to 1).

```{r,echo=FALSE}
mu_maxenergy <- ddply(corrected_seismic,"class", summarise, grp.mean=mean(maxenergy))
corrected_seismic %>%
  mutate(class = as.character(class)) %>%
  mutate(maxenergy_tran = maxenergy+1) %>%
  ggplot(aes(maxenergy_tran,fill=class)) +
  geom_density(alpha=0.4) +
  geom_vline(data=mu_maxenergy, aes(xintercept=grp.mean, color=class),
             linetype="dashed") +
  scale_x_continuous(trans = "log10") +
  xlab("log(Maxium energy of the seismic bumps in previous shift) / J") +
  theme_bw() +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  ggtitle("Maximum energy of the seismic bumps in previous shift on mine with\nhazardous state (class 1) and non-hazardous state (class 0)")
```

Here we can calculate the ratio of 'maximum energy' to 'total energy' and see how it matches our prediction. 

```{r, echo=TRUE}
corrected_seismic %>%
  mutate(maxenergy=maxenergy+1) %>%
  mutate(energy=energy+1) %>%
  mutate(max_to_total = maxenergy/energy) %>%
  summarize(mean(max_to_total))
```


### 2.2.12 Correlation between numeric variables

Up to now we have visualized how different attributes affect the state of mine (hazardous when it is likely that a high energy seismic bump would occur in the next shift; non-hazardous when it is likely that a high energy seismic bump would not occur in the next shift). However we haven't seen the correlation between attributes. Here a correlation matrix is generated to see how attributes are correlate to each other.

```{r, include=FALSE}
NumericVariables<- corrected_seismic %>%
  select(genergy,gpuls,gdenergy,gdpuls,energy,maxenergy)
```

```{r, echo=FALSE}
corrplot.mixed(cor(NumericVariables), lower.col = "black", number.cex = .7)
```

From the graph above we can see that there are 3 pairs of attributes that are closely correlate to each other.

```{r, echo=FALSE}
kable(data.frame(pairs=c("energy~maxenergy","gdenergy~gdpuls","genergy~gpuls"),
                 correlation = c(0.99,0.81,0.75)))
```



## 2.3 Modeling Approach

### 2.3.1 Potential problem in data set

As mentioned in section 1.3, imbalance of class variables is a great problem in the data set. Among `r nrow(seismic)` observations, only `r sum(seismic$class==1)` of them belongs to class 1. Therefore if every time we just keep guessing the zero (the negative class), the result would be quite accurate or even perform better than other machine learning methods. Section 2.3.2 will demonstrate that problem.

### 2.3.2 Model - All Zero (with imbalance class)

In our first model we would try a naive and simple method by just guessing zero (the negative class) as the output every time. It is expected that most of time we will get the correct answer. The accuracy is calculated as follow.

```{r, echo=TRUE}
model_zero <- 0
mean(model_zero == corrected_seismic$class)
```

From the result, an accuracy of `r mean(model_zero == corrected_seismic$class)` is obtained. 

### 2.3.3 A solution to imbalance number of class variables

There are many ways to deal with class imbalance problem such as collecting more data, changing the performance metric, resampling data set, generating synthetic samples, using different algorithms and penalizing models [3]. In this report, resampling would be used for creating new examples in the minority class and randomly selecting a number of cases from the majority class with the help of Synthetic minority over-sampling technique. 

```{r, include=FALSE}
corrected_seismic$class <- as.factor(corrected_seismic$class)
corrected_seismic$seismic <- as.factor(corrected_seismic$seismic)
corrected_seismic$seismoacoustic <- as.factor(corrected_seismic$seismoacoustic)
corrected_seismic$shift <- as.factor(corrected_seismic$shift)
corrected_seismic$ghazard <- as.factor(corrected_seismic$ghazard)
```

Here the SMOTE (Synthetic minority over-sampling technique) Algorithm from DMwR package is used for resampling.

```{r, echo=TRUE}
re_seismic <- SMOTE(class ~ ., corrected_seismic, perc.over = 200, k = 5, perc.under=150)
```

After resampling, we now have `r sum(re_seismic$class==1)` positive class and `r sum(re_seismic$class==0)` negative class. The data set now becomes balance and allows us to perform machine learning algorithm.

```{r, echo=TRUE}
sum(re_seismic$class==1)
```

```{r, echo=TRUE}
sum(re_seismic$class==0)
```

### 2.3.4 Model - All Zero

After resampling our data set with same number of positive and negative class, an accuracy of 0.5 would be resulted by using the model that always predict zero.

```{r, echo=TRUE}
mean(model_zero == re_seismic$class)
```

### 2.3.5 Data Partition 

In order to evaluate our model performance, it is required to split our data set into training set and test set. A partition of 80 percent of training data to 20 percent of test data would be chosen.

```{r, echo=TRUE}
y <- re_seismic$class
set.seed(1)
test_index <- createDataPartition(y, times = 1, p = 0.2, list = FALSE)
re_seismic_train <- re_seismic %>% slice(-test_index)
re_seismic_test <- re_seismic %>% slice(test_index)
```

We have now `r nrow(re_seismic_train)` training data and `r nrow(re_seismic_test)` test data. In the following sections, we would try different training methods and see evaluate their performance.

During the training process, Repeated k-fold Cross Validation will be used in order to tune the hyper-parameters to best values. This is the repeated process of splitting the data into k-folds, and the final model accuracy is calculated as the mean from the numbers of repeats which should be more objective. For the following training, 10-fold cross validation with 3 repeats will be used for our data set.

### 2.3.6 Model - KNN

Here, k nearest neighbors is used to build our classification model. KNN classifier first computes the distance between a test data and all instances in the training data, after that k closest instances are selected and the result is voted by the most frequent label (or class). In a data set, observations within the same class should also be closer to each other in high-dimensional feature spaces. This characteristic is suitable for solving binary classification problem.

As the number of nearest neighbors is a key factor to knn algorithm, it is set to be 3 to 10. With the repeated cross-validation test, the best k would be obtained.

```{r, echo=TRUE}
set.seed(1)
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)
fit_knn <- train(class~., 
                 data = re_seismic_train, 
                 trControl = train_control,
                 method = "knn",
                 tuneGrid = data.frame(k = seq(3, 10, 1))) 
```

Below is the graph showing the accuracy in repeated cross-validation test with different numbers of neighbors. 

```{r, echo=TRUE}
ggplot(fit_knn)
```

And the best number of neighbors is `r fit_knn$bestTune` for this model.

``` {r,echo=TRUE}
fit_knn$bestTune
```

Now in test set, we use the trained model to predict the output and compare with the actual output. The accuracy is then evaluated.

```{r, echo=TRUE}
predict_knn <- 
  re_seismic_test %>%
  mutate(y_hat = predict(fit_knn, newdata = re_seismic_test)) %>%
  pull(y_hat) %>%
  factor(levels = levels(re_seismic_test$class))
cm_knn <- confusionMatrix(predict_knn, re_seismic_test$class)
cm_knn$overall["Accuracy"]
```

The overall accuracy of knn model is `r cm_knn$overall["Accuracy"]`.

### 2.3.7 Model - Decision Tree (ID3)

We will build model with Decision tree (ID3) algorithm in this section. Decision Tree split the data on the feature that results in the largest information gain. In the previous data exploration section, we can easily observe that some features like 'gpuls', 'genergy' and 'energy' have different distribution in positive class and negative class, which implies that they can provide useful information to learner to classify data set. 

For training, a complexity parameter 'cp' ranged from 0 to 0.1 is used in repeated cross-validation test for fine tune.

```{r, echo=TRUE}
set.seed(1)
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)
fit_rpart <- train(class~., 
                   data = re_seismic_train, 
                   trControl = train_control,
                   tuneGrid = data.frame(cp = seq(0, 0.1, 0.005)),
                   method = "rpart")
```

The below graph shows the relationship between complexity parameter and accuracy in repeated cross-validation test.

```{r, echo = TRUE}
ggplot(fit_rpart)
```

The best value for complexity parameter is `r fit_rpart$bestTune`.

```{r, echo = TRUE}
fit_rpart$bestTune
```

The trained model is then used to predict the output in test set. Accuracy is then calculated by comparing the result with actual output. 

```{r, echo = TRUE}
predict_rpart <- 
  re_seismic_test %>%
  mutate(y_hat = predict(fit_rpart, newdata = re_seismic_test)) %>%
  pull(y_hat) %>%
  factor(levels = levels(re_seismic_test$class))
cm_rpart <- confusionMatrix(predict_rpart, re_seismic_test$class)
cm_rpart$overall["Accuracy"]
```

The overall accuracy of decision tree model is `r cm_rpart$overall["Accuracy"]`.

### 2.3.8 Model - Random Forest

The final machine training method used for training is Random Forest (RF).  Comparing to decision knn and tree, RF is powerful because it is an ensemble model using Bagging (Boostrap + Aggregating) as the ensemble method and decision tree as the individual learner. RF use Boostrap sampling technique by randomly sampling training data with replacement, results in some data may appear several times. RF helps to create data randomness and feature randomness. Once the set of decision trees are trained, the output of the forest is obtained by the majority vote of the trees. 

The mtry parameter, which is the number of variables available for splitting at each tree node, are ranged from 1 to 10 in repeated cross-validation test for fine tune.

```{r, echo = TRUE}
set.seed(1)
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)

fit_rf <- 
  train(class~., 
  data = re_seismic_train, 
  method = "rf",
  tuneGrid = data.frame(mtry = seq(1:10)), 
  trControl = train_control,
  ntree = 500)
```

The below graph shows how the parameter mtry affects the accuracy of model in repeated cross-validation test.

```{r, echo = TRUE}
plot(fit_rf)
```

The result shows that the best value of mtry is `r fit_rf$bestTune`.

```{r, echo = TRUE}
fit_rf$bestTune
```

After our ensemble model is trained with train set, it used to predict result in test set.

```{r, echo = TRUE}
predict_rf <- 
  re_seismic_test %>%
  mutate(y_hat = predict(fit_rf, newdata = re_seismic_test)) %>%
  pull(y_hat) %>%
  factor(levels = levels(re_seismic_test$class))
    
cm_rf <- confusionMatrix(predict_rf, re_seismic_test$class)
cm_rf$overall["Accuracy"]
```

The overall accuracy of random forest model is `r cm_rf$overall["Accuracy"]`.



***

# 3. Results and Discussion

After balancing the data set, we have built 4 models. They are 1. All Zero; 2. KNN; 3. Decision Tree (ID3); 4. Random Forest. To evaluate the models, overall accuracy and ROC curve would be compared and discussed in the following sections. After evaluation, it will be interesting to see the importance of each feature in the trained models. 

## 3.1 Overall Accuracy

```{r, echo=FALSE}
df_acc <- data.frame(Model = c("All Zero", "KNN", "Decision Tree", "Random Forest"),
                     Accuracy = c(0.5,
                                  cm_knn$overall["Accuracy"],
                                  cm_rpart$overall["Accuracy"],
                                  cm_rf$overall["Accuracy"]))

kable(df_acc, caption = "Overall Accuracy in different Models")
```

In this section we would compare the overall accuracy between the four models. From Table 4, we can observe that Random Forest (RF) is the most powerful classifier among the four models. Comparing with the second best model - Decision Tree, RF get an improvement in overall accuracy for about 10 percent! While the decision tree model just perform about 4% better than the knn model. 

RF is the most powerful because it is an ensemble model which build up with large amount of decision trees (individual classifier). As algorithm of decision tree is sensitive or highly depends on the information entropy in the data set, small changes in the training data could cause large changes to decision logic. Therefore with only one decision tree, the model would suffer from the bias of data set easily. However in RF, the boostrap sampling allows classifiers to see different data also with different attributes, such kind of randomness lower the bias effects produced in the data set and hence give a more accurate result. 

Among the three machine learning algorithm, knn perform the worst in overall accuracy. This may due to the different types of features in the data set. Some features are categorized to 0 or 1 but some are numeric, which causes different scale of variables appears in the data set. Moreover the presence of outliers in data set would greatly affect the configuration of training data in high-dimensional vector space when lower the accuracy in classification task.

## 3.2 ROC Curve

Next we would compare the ROC (Receiver Operating Characteristic) curve between the models. 


```{r, echo = TRUE, warning=FALSE}
#generate ROC curve for knn
pROC_knn <- roc(re_seismic_test$class, as.numeric(predict_knn), 
                  ci = TRUE, ci.alpha = 0.9, stratifies = FALSE, plot = TRUE, 
                  auc.polygon = TRUE, max.auc.polygon = TRUE, grid = TRUE,
                  print.auc = TRUE, show.thres = TRUE)
#confidence interval of ROC
sens.ci_knn <- ci.se(pROC_knn)
#plot the ROC curve
plot(sens.ci_knn, type = "shape", col = "gold")
plot(sens.ci_knn, type = "bars")
```

```{r, echo = TRUE, warning=FALSE}
#generate ROC curve for knn
pROC_rpart <- roc(re_seismic_test$class, as.numeric(predict_rpart), 
                  ci = TRUE, ci.alpha = 0.9, stratifies = FALSE, plot = TRUE, 
                  auc.polygon = TRUE, max.auc.polygon = TRUE, grid = TRUE,
                  print.auc = TRUE, show.thres = TRUE)
#confidence interval of ROC
sens.ci_rpart <- ci.se(pROC_rpart)
#plot the ROC curve
plot(sens.ci_rpart, type = "shape", col = "gold")
plot(sens.ci_rpart, type = "bars")
```

```{r}
#generate ROC curve for random forest
pROC_rf <- roc(re_seismic_test$class, as.numeric(predict_rf), 
                  ci = TRUE, ci.alpha = 0.9, stratifies = FALSE, plot = TRUE, 
                  auc.polygon = TRUE, max.auc.polygon = TRUE, grid = TRUE,
                  print.auc = TRUE, show.thres = TRUE)
#confidence interval of ROC
sens.ci_rf <- ci.se(pROC_rf)
#plot the ROC curve
plot(sens.ci_rf, type = "shape", col = "gold")
plot(sens.ci_rf, type = "bars")
```

## 3.3 Importance of features 



***
# 4. Conclusion and Future Work

## 4.1 Limitation
More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard prediction methods. 
Accuracy of so far created methods is however far from perfect. 
Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number 
of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict 
seismic hazard
Therefore, it is essential to search for new opportunities of better hazard prediction, 
also using machine learning methods.
Unbalanced distribution of positive ('hazardous state') and negative 
('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used 
methods are still insufficient to achieve good sensitivity and specificity of predictions.

***

# Aknowledgement
Marek Sikora^{1,2} (marek.sikora '@' polsl.pl), Lukasz Wrobel^{1} (lukasz.wrobel '@' polsl.pl) 
(1) Institute of Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland 
(2) Institute of Innovative Technologies EMAG, 40-189 Katowice, Poland

***

# Reference

* 1. Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the 
Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 
918-928
* 2. Kabiesz, J.: Effect 
of the form of data on the quality of mine tremors hazard forecasting using neural networks. 
Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147
* 3. <https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/>
